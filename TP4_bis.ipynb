{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa4c0c2-fe2a-4b5b-9545-10344fde1f21",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/fr/thumb/e/ed/Logo_Universit%C3%A9_du_Maine.svg/1280px-Logo_Universit%C3%A9_du_Maine.svg.png' width=\"300\" height=\"500\">\n",
    "<br>\n",
    "<div style=\"border: solid 3px #000;\">\n",
    "    <h1 style=\"text-align: center; color:#000; font-family:Georgia; font-size:26px;\">Infrastructures pour l'IA</h1>\n",
    "    <p style='text-align: center;'>Master Informatique 1</p>\n",
    "    <p style='text-align: center;'>Anhony Larcher</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371ccdef-4839-4ddc-a986-dfcc76fe8449",
   "metadata": {},
   "source": [
    "Dans cet exercice nous allons classifier les image sde la base de données MNIST un réseau de neurones profonds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e9a4e-2f0b-4219-967b-d8ff778f476d",
   "metadata": {},
   "source": [
    "## Importez un package qui vous permette de tracer ces graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "676ce173-77ca-4d56-a425-e3c5543d328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo...\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a9c540-fe09-4d1c-b4a0-c177f9966236",
   "metadata": {},
   "source": [
    "## Importez PyTorch et téléchargez MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02bd1b38-e1b3-4f07-92fc-e49d7b44a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the test dataset\n",
    "test_set = datasets.MNIST(root = './',\n",
    "                          download = True, train = False, transform = transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd72570-9be8-488c-8714-b530b458be54",
   "metadata": {},
   "source": [
    "# Préparez les données d'apprentissage et de développement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0b32817-a4be-4286-9e48-825a75bc2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST('./files/', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "                                       \n",
    "                                       \n",
    "validation_set = torchvision.datasets.MNIST('./files/', train=False, download=True, transform=transform)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8dc6b7-5564-44b3-84e6-21bd6d6c48c3",
   "metadata": {},
   "source": [
    "# Regardez quelques données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "003def73-9f79-4b79-bd55-a61eff68c9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a219d980-9360-42fe-8619-7f0deeb2c74f",
   "metadata": {},
   "source": [
    "## Visualisez quelques exemples de MNIST\n",
    "Chaque ligne de X est un vecteur qui contient les 784 valeurs des pixels d'une image 28x28 en niveaux de gris\n",
    "\n",
    "Affichez les 4 premiers exemples de cette base de données avec leur label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b62598-ee63-4c44-9d38-9946b1470ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b90f2ba-b7fa-4571-9aa0-13d6ac748dea",
   "metadata": {},
   "source": [
    "# Créez un réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dda26921-f970-452a-bc33-a47fb6db0cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(Net, self).__init__()\n",
    "\n",
    "      # First 2D convolutional layer, taking in 1 input channel (image),\n",
    "      # outputting 32 convolutional features, with a square kernel size of 3\n",
    "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "      # Second 2D convolutional layer, taking in the 32 input layers,\n",
    "      # outputting 64 convolutional features, with a square kernel size of 3\n",
    "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "\n",
    "      # Designed to ensure that adjacent pixels are either all 0s or all active\n",
    "      # with an input probability\n",
    "      self.dropout1 = nn.Dropout2d(0.25)\n",
    "      self.dropout2 = nn.Dropout2d(0.5)\n",
    "\n",
    "      # First fully connected layer\n",
    "      self.fc1 = nn.Linear(9216, 128)\n",
    "      # Second fully connected layer that outputs our 10 labels\n",
    "      self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, x):\n",
    "      # Pass data through conv1\n",
    "      x = self.conv1(x)\n",
    "      # Use the rectified-linear activation function over x\n",
    "      x = F.relu(x)\n",
    "\n",
    "      x = self.conv2(x)\n",
    "      x = F.relu(x)\n",
    "\n",
    "      # Run max pooling over x\n",
    "      x = F.max_pool2d(x, 2)\n",
    "      # Pass data through dropout1\n",
    "      x = self.dropout1(x)\n",
    "      # Flatten x with start_dim=1\n",
    "      x = torch.flatten(x, 1)\n",
    "      # Pass data through fc1\n",
    "      x = self.fc1(x)\n",
    "      x = F.relu(x)\n",
    "      x = self.dropout2(x)\n",
    "      x = self.fc2(x)\n",
    "\n",
    "      # Apply softmax to x\n",
    "      output = F.log_softmax(x, dim=1)\n",
    "      return output\n",
    "    \n",
    "    \n",
    "network = Net()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728eb67-8c89-4748-84e8-abe58f88017a",
   "metadata": {},
   "source": [
    "# Testez votre réseau en passant des données dedans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b52cf93c-4225-4ce6-9f75-5b76d1cd2ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1846, -2.3707, -2.4302, -2.2747, -2.4089, -2.1912, -2.3275, -2.3799,\n",
      "         -2.2473, -2.2468]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Equates to one random 28x28 image\n",
    "random_data = torch.rand((1, 1, 28, 28))\n",
    "\n",
    "network = Net()\n",
    "result = network(random_data)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f67030-8387-4be9-b055-82b9d7962a94",
   "metadata": {},
   "source": [
    "# Créez un optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdfcb312-ef5e-45a2-8770-9743f9f94776",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "n_epochs = 10\n",
    "optimizer = optim.SGD(network.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b942dd-4235-4483-9fe8-025249e6af04",
   "metadata": {},
   "source": [
    "# Entrainez votre réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c547738-fb20-4609-a1a3-a8e32728c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "validation_losses = []\n",
    "validation_counter = [i*len(validation_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76594e2f-78b8-4246-886b-e519ee425bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(network.state_dict(), './results/model.pth')\n",
    "      torch.save(optimizer.state_dict(), './results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f7aff64-1299-4f5a-beeb-afe83650b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "  network.eval()\n",
    "  validation_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in validation_loader:\n",
    "      output = network(data)\n",
    "      validation_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  validation_loss /= len(validation_loader.dataset)\n",
    "  validation_losses.append(validation_loss)\n",
    "  print('\\nValidation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    validation_loss, correct, len(validation_loader.dataset),\n",
    "    100. * correct / len(validation_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e4e76e-919f-48ba-8b95-a222eee7183c",
   "metadata": {},
   "source": [
    "# Boucle d'apprentissage\n",
    "\n",
    "On teste une première fois le modèle avec des paramètres aléatoires avant l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b189125a-1236-454c-983f-f1ace9547a2c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Avg. loss: 2.3091, Accuracy: 1268/10000 (13%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305466\n",
      "Train Epoch: 1 [160/60000 (0%)]\tLoss: 2.318041\n",
      "Train Epoch: 1 [320/60000 (1%)]\tLoss: 2.316295\n",
      "Train Epoch: 1 [480/60000 (1%)]\tLoss: 2.297769\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.244444\n",
      "Train Epoch: 1 [800/60000 (1%)]\tLoss: 2.257447\n",
      "Train Epoch: 1 [960/60000 (2%)]\tLoss: 2.214033\n",
      "Train Epoch: 1 [1120/60000 (2%)]\tLoss: 2.250761\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.224579\n",
      "Train Epoch: 1 [1440/60000 (2%)]\tLoss: 2.134953\n",
      "Train Epoch: 1 [1600/60000 (3%)]\tLoss: 2.272814\n",
      "Train Epoch: 1 [1760/60000 (3%)]\tLoss: 2.196261\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.192069\n",
      "Train Epoch: 1 [2080/60000 (3%)]\tLoss: 2.027404\n",
      "Train Epoch: 1 [2240/60000 (4%)]\tLoss: 2.118821\n",
      "Train Epoch: 1 [2400/60000 (4%)]\tLoss: 2.043605\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.114543\n",
      "Train Epoch: 1 [2720/60000 (5%)]\tLoss: 2.037032\n",
      "Train Epoch: 1 [2880/60000 (5%)]\tLoss: 2.134428\n",
      "Train Epoch: 1 [3040/60000 (5%)]\tLoss: 2.065431\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 1.932265\n",
      "Train Epoch: 1 [3360/60000 (6%)]\tLoss: 1.950191\n",
      "Train Epoch: 1 [3520/60000 (6%)]\tLoss: 1.823462\n",
      "Train Epoch: 1 [3680/60000 (6%)]\tLoss: 1.731484\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.701524\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.731959\n",
      "Train Epoch: 1 [4160/60000 (7%)]\tLoss: 1.768364\n",
      "Train Epoch: 1 [4320/60000 (7%)]\tLoss: 1.480239\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 1.321599\n",
      "Train Epoch: 1 [4640/60000 (8%)]\tLoss: 1.556481\n",
      "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 1.413940\n",
      "Train Epoch: 1 [4960/60000 (8%)]\tLoss: 1.547037\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.126048\n",
      "Train Epoch: 1 [5280/60000 (9%)]\tLoss: 1.182854\n",
      "Train Epoch: 1 [5440/60000 (9%)]\tLoss: 0.940671\n",
      "Train Epoch: 1 [5600/60000 (9%)]\tLoss: 1.273698\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.013954\n",
      "Train Epoch: 1 [5920/60000 (10%)]\tLoss: 1.224392\n",
      "Train Epoch: 1 [6080/60000 (10%)]\tLoss: 1.191711\n",
      "Train Epoch: 1 [6240/60000 (10%)]\tLoss: 1.054385\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.246363\n",
      "Train Epoch: 1 [6560/60000 (11%)]\tLoss: 1.051744\n",
      "Train Epoch: 1 [6720/60000 (11%)]\tLoss: 0.998614\n",
      "Train Epoch: 1 [6880/60000 (11%)]\tLoss: 0.798223\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.152919\n",
      "Train Epoch: 1 [7200/60000 (12%)]\tLoss: 0.910411\n",
      "Train Epoch: 1 [7360/60000 (12%)]\tLoss: 1.258488\n",
      "Train Epoch: 1 [7520/60000 (13%)]\tLoss: 0.699908\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.922886\n",
      "Train Epoch: 1 [7840/60000 (13%)]\tLoss: 1.225678\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.806852\n",
      "Train Epoch: 1 [8160/60000 (14%)]\tLoss: 0.886261\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.756537\n",
      "Train Epoch: 1 [8480/60000 (14%)]\tLoss: 1.399224\n",
      "Train Epoch: 1 [8640/60000 (14%)]\tLoss: 0.897551\n",
      "Train Epoch: 1 [8800/60000 (15%)]\tLoss: 0.631189\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.686605\n",
      "Train Epoch: 1 [9120/60000 (15%)]\tLoss: 0.763924\n",
      "Train Epoch: 1 [9280/60000 (15%)]\tLoss: 0.727930\n",
      "Train Epoch: 1 [9440/60000 (16%)]\tLoss: 1.072664\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.699426\n",
      "Train Epoch: 1 [9760/60000 (16%)]\tLoss: 0.685884\n",
      "Train Epoch: 1 [9920/60000 (17%)]\tLoss: 0.488769\n",
      "Train Epoch: 1 [10080/60000 (17%)]\tLoss: 0.827001\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.408532\n",
      "Train Epoch: 1 [10400/60000 (17%)]\tLoss: 0.825968\n",
      "Train Epoch: 1 [10560/60000 (18%)]\tLoss: 0.701581\n",
      "Train Epoch: 1 [10720/60000 (18%)]\tLoss: 0.535867\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.882542\n",
      "Train Epoch: 1 [11040/60000 (18%)]\tLoss: 0.577594\n",
      "Train Epoch: 1 [11200/60000 (19%)]\tLoss: 0.949720\n",
      "Train Epoch: 1 [11360/60000 (19%)]\tLoss: 0.386596\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.448488\n",
      "Train Epoch: 1 [11680/60000 (19%)]\tLoss: 0.286145\n",
      "Train Epoch: 1 [11840/60000 (20%)]\tLoss: 0.983417\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.826722\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.715569\n",
      "Train Epoch: 1 [12320/60000 (21%)]\tLoss: 0.470869\n",
      "Train Epoch: 1 [12480/60000 (21%)]\tLoss: 0.308053\n",
      "Train Epoch: 1 [12640/60000 (21%)]\tLoss: 0.423382\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.531738\n",
      "Train Epoch: 1 [12960/60000 (22%)]\tLoss: 0.240781\n",
      "Train Epoch: 1 [13120/60000 (22%)]\tLoss: 0.623999\n",
      "Train Epoch: 1 [13280/60000 (22%)]\tLoss: 0.735251\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.438226\n",
      "Train Epoch: 1 [13600/60000 (23%)]\tLoss: 0.451158\n",
      "Train Epoch: 1 [13760/60000 (23%)]\tLoss: 0.691350\n",
      "Train Epoch: 1 [13920/60000 (23%)]\tLoss: 0.669488\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.490436\n",
      "Train Epoch: 1 [14240/60000 (24%)]\tLoss: 0.495491\n",
      "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.240658\n",
      "Train Epoch: 1 [14560/60000 (24%)]\tLoss: 0.701281\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.156903\n",
      "Train Epoch: 1 [14880/60000 (25%)]\tLoss: 0.593129\n",
      "Train Epoch: 1 [15040/60000 (25%)]\tLoss: 1.126195\n",
      "Train Epoch: 1 [15200/60000 (25%)]\tLoss: 0.590507\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.429229\n",
      "Train Epoch: 1 [15520/60000 (26%)]\tLoss: 0.389495\n",
      "Train Epoch: 1 [15680/60000 (26%)]\tLoss: 0.557137\n",
      "Train Epoch: 1 [15840/60000 (26%)]\tLoss: 0.457531\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.845125\n",
      "Train Epoch: 1 [16160/60000 (27%)]\tLoss: 0.465644\n",
      "Train Epoch: 1 [16320/60000 (27%)]\tLoss: 0.428268\n",
      "Train Epoch: 1 [16480/60000 (27%)]\tLoss: 0.223562\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.380553\n",
      "Train Epoch: 1 [16800/60000 (28%)]\tLoss: 0.407305\n",
      "Train Epoch: 1 [16960/60000 (28%)]\tLoss: 0.366445\n",
      "Train Epoch: 1 [17120/60000 (29%)]\tLoss: 0.441909\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.834017\n",
      "Train Epoch: 1 [17440/60000 (29%)]\tLoss: 0.472544\n",
      "Train Epoch: 1 [17600/60000 (29%)]\tLoss: 0.643965\n",
      "Train Epoch: 1 [17760/60000 (30%)]\tLoss: 0.425580\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.499228\n",
      "Train Epoch: 1 [18080/60000 (30%)]\tLoss: 0.562669\n",
      "Train Epoch: 1 [18240/60000 (30%)]\tLoss: 0.518577\n",
      "Train Epoch: 1 [18400/60000 (31%)]\tLoss: 0.450315\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.575324\n",
      "Train Epoch: 1 [18720/60000 (31%)]\tLoss: 0.345648\n",
      "Train Epoch: 1 [18880/60000 (31%)]\tLoss: 0.516234\n",
      "Train Epoch: 1 [19040/60000 (32%)]\tLoss: 0.186392\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.669148\n",
      "Train Epoch: 1 [19360/60000 (32%)]\tLoss: 0.791298\n",
      "Train Epoch: 1 [19520/60000 (33%)]\tLoss: 0.428556\n",
      "Train Epoch: 1 [19680/60000 (33%)]\tLoss: 0.261377\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.228690\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.476533\n",
      "Train Epoch: 1 [20160/60000 (34%)]\tLoss: 0.156422\n",
      "Train Epoch: 1 [20320/60000 (34%)]\tLoss: 0.247092\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.467420\n",
      "Train Epoch: 1 [20640/60000 (34%)]\tLoss: 0.380746\n",
      "Train Epoch: 1 [20800/60000 (35%)]\tLoss: 0.533341\n",
      "Train Epoch: 1 [20960/60000 (35%)]\tLoss: 0.288696\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.242123\n",
      "Train Epoch: 1 [21280/60000 (35%)]\tLoss: 0.602067\n",
      "Train Epoch: 1 [21440/60000 (36%)]\tLoss: 0.351726\n",
      "Train Epoch: 1 [21600/60000 (36%)]\tLoss: 0.495637\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.109313\n",
      "Train Epoch: 1 [21920/60000 (37%)]\tLoss: 0.764468\n",
      "Train Epoch: 1 [22080/60000 (37%)]\tLoss: 0.603617\n",
      "Train Epoch: 1 [22240/60000 (37%)]\tLoss: 0.327009\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.336496\n",
      "Train Epoch: 1 [22560/60000 (38%)]\tLoss: 0.845599\n",
      "Train Epoch: 1 [22720/60000 (38%)]\tLoss: 0.225200\n",
      "Train Epoch: 1 [22880/60000 (38%)]\tLoss: 0.260653\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.373760\n",
      "Train Epoch: 1 [23200/60000 (39%)]\tLoss: 1.001039\n",
      "Train Epoch: 1 [23360/60000 (39%)]\tLoss: 0.303935\n",
      "Train Epoch: 1 [23520/60000 (39%)]\tLoss: 0.356068\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.215780\n",
      "Train Epoch: 1 [23840/60000 (40%)]\tLoss: 0.405685\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.168641\n",
      "Train Epoch: 1 [24160/60000 (40%)]\tLoss: 0.198428\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.709074\n",
      "Train Epoch: 1 [24480/60000 (41%)]\tLoss: 0.392394\n",
      "Train Epoch: 1 [24640/60000 (41%)]\tLoss: 0.746346\n",
      "Train Epoch: 1 [24800/60000 (41%)]\tLoss: 0.194516\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.465962\n",
      "Train Epoch: 1 [25120/60000 (42%)]\tLoss: 0.391271\n",
      "Train Epoch: 1 [25280/60000 (42%)]\tLoss: 0.419419\n",
      "Train Epoch: 1 [25440/60000 (42%)]\tLoss: 0.326791\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.459326\n",
      "Train Epoch: 1 [25760/60000 (43%)]\tLoss: 0.560306\n",
      "Train Epoch: 1 [25920/60000 (43%)]\tLoss: 0.285089\n",
      "Train Epoch: 1 [26080/60000 (43%)]\tLoss: 0.274569\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.117799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [26400/60000 (44%)]\tLoss: 1.125444\n",
      "Train Epoch: 1 [26560/60000 (44%)]\tLoss: 0.314713\n",
      "Train Epoch: 1 [26720/60000 (45%)]\tLoss: 0.236983\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.522305\n",
      "Train Epoch: 1 [27040/60000 (45%)]\tLoss: 0.724335\n",
      "Train Epoch: 1 [27200/60000 (45%)]\tLoss: 0.128479\n",
      "Train Epoch: 1 [27360/60000 (46%)]\tLoss: 0.738186\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.645609\n",
      "Train Epoch: 1 [27680/60000 (46%)]\tLoss: 0.211003\n",
      "Train Epoch: 1 [27840/60000 (46%)]\tLoss: 0.157986\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.356508\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.392213\n",
      "Train Epoch: 1 [28320/60000 (47%)]\tLoss: 0.211621\n",
      "Train Epoch: 1 [28480/60000 (47%)]\tLoss: 0.443326\n",
      "Train Epoch: 1 [28640/60000 (48%)]\tLoss: 0.492638\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.342382\n",
      "Train Epoch: 1 [28960/60000 (48%)]\tLoss: 0.610679\n",
      "Train Epoch: 1 [29120/60000 (49%)]\tLoss: 0.233548\n",
      "Train Epoch: 1 [29280/60000 (49%)]\tLoss: 0.544754\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.516259\n",
      "Train Epoch: 1 [29600/60000 (49%)]\tLoss: 0.088395\n",
      "Train Epoch: 1 [29760/60000 (50%)]\tLoss: 0.401674\n",
      "Train Epoch: 1 [29920/60000 (50%)]\tLoss: 0.111053\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.206651\n",
      "Train Epoch: 1 [30240/60000 (50%)]\tLoss: 0.287511\n",
      "Train Epoch: 1 [30400/60000 (51%)]\tLoss: 0.570899\n",
      "Train Epoch: 1 [30560/60000 (51%)]\tLoss: 0.979353\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.359573\n",
      "Train Epoch: 1 [30880/60000 (51%)]\tLoss: 0.924006\n",
      "Train Epoch: 1 [31040/60000 (52%)]\tLoss: 0.314579\n",
      "Train Epoch: 1 [31200/60000 (52%)]\tLoss: 0.189065\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.271511\n",
      "Train Epoch: 1 [31520/60000 (53%)]\tLoss: 0.626241\n",
      "Train Epoch: 1 [31680/60000 (53%)]\tLoss: 0.392322\n",
      "Train Epoch: 1 [31840/60000 (53%)]\tLoss: 0.091870\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.148896\n",
      "Train Epoch: 1 [32160/60000 (54%)]\tLoss: 0.272602\n",
      "Train Epoch: 1 [32320/60000 (54%)]\tLoss: 0.275717\n",
      "Train Epoch: 1 [32480/60000 (54%)]\tLoss: 0.747299\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 1.132775\n",
      "Train Epoch: 1 [32800/60000 (55%)]\tLoss: 0.167413\n",
      "Train Epoch: 1 [32960/60000 (55%)]\tLoss: 0.084349\n",
      "Train Epoch: 1 [33120/60000 (55%)]\tLoss: 0.208425\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.226270\n",
      "Train Epoch: 1 [33440/60000 (56%)]\tLoss: 0.400556\n",
      "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.408984\n",
      "Train Epoch: 1 [33760/60000 (56%)]\tLoss: 0.476388\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.428997\n",
      "Train Epoch: 1 [34080/60000 (57%)]\tLoss: 0.417462\n",
      "Train Epoch: 1 [34240/60000 (57%)]\tLoss: 0.266473\n",
      "Train Epoch: 1 [34400/60000 (57%)]\tLoss: 0.298035\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.271619\n",
      "Train Epoch: 1 [34720/60000 (58%)]\tLoss: 0.194888\n",
      "Train Epoch: 1 [34880/60000 (58%)]\tLoss: 0.527358\n",
      "Train Epoch: 1 [35040/60000 (58%)]\tLoss: 0.234525\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.104328\n",
      "Train Epoch: 1 [35360/60000 (59%)]\tLoss: 0.640425\n",
      "Train Epoch: 1 [35520/60000 (59%)]\tLoss: 0.589970\n",
      "Train Epoch: 1 [35680/60000 (59%)]\tLoss: 0.466290\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.694121\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.163686\n",
      "Train Epoch: 1 [36160/60000 (60%)]\tLoss: 0.971832\n",
      "Train Epoch: 1 [36320/60000 (61%)]\tLoss: 0.345478\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.398839\n",
      "Train Epoch: 1 [36640/60000 (61%)]\tLoss: 0.278743\n",
      "Train Epoch: 1 [36800/60000 (61%)]\tLoss: 0.696353\n",
      "Train Epoch: 1 [36960/60000 (62%)]\tLoss: 0.405317\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.301800\n",
      "Train Epoch: 1 [37280/60000 (62%)]\tLoss: 0.384533\n",
      "Train Epoch: 1 [37440/60000 (62%)]\tLoss: 0.296123\n",
      "Train Epoch: 1 [37600/60000 (63%)]\tLoss: 0.172297\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.183138\n",
      "Train Epoch: 1 [37920/60000 (63%)]\tLoss: 0.114995\n",
      "Train Epoch: 1 [38080/60000 (63%)]\tLoss: 0.374110\n",
      "Train Epoch: 1 [38240/60000 (64%)]\tLoss: 1.013124\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.366778\n",
      "Train Epoch: 1 [38560/60000 (64%)]\tLoss: 0.178816\n",
      "Train Epoch: 1 [38720/60000 (65%)]\tLoss: 0.847691\n",
      "Train Epoch: 1 [38880/60000 (65%)]\tLoss: 0.274654\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.498837\n",
      "Train Epoch: 1 [39200/60000 (65%)]\tLoss: 0.363442\n",
      "Train Epoch: 1 [39360/60000 (66%)]\tLoss: 0.529088\n",
      "Train Epoch: 1 [39520/60000 (66%)]\tLoss: 0.104210\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.318089\n",
      "Train Epoch: 1 [39840/60000 (66%)]\tLoss: 0.259552\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.319407\n",
      "Train Epoch: 1 [40160/60000 (67%)]\tLoss: 0.610694\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.272926\n",
      "Train Epoch: 1 [40480/60000 (67%)]\tLoss: 0.509188\n",
      "Train Epoch: 1 [40640/60000 (68%)]\tLoss: 0.138084\n",
      "Train Epoch: 1 [40800/60000 (68%)]\tLoss: 0.397369\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.268446\n",
      "Train Epoch: 1 [41120/60000 (69%)]\tLoss: 0.191144\n",
      "Train Epoch: 1 [41280/60000 (69%)]\tLoss: 0.361510\n",
      "Train Epoch: 1 [41440/60000 (69%)]\tLoss: 0.236322\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.313329\n",
      "Train Epoch: 1 [41760/60000 (70%)]\tLoss: 0.176287\n",
      "Train Epoch: 1 [41920/60000 (70%)]\tLoss: 0.271617\n",
      "Train Epoch: 1 [42080/60000 (70%)]\tLoss: 0.453525\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.388725\n",
      "Train Epoch: 1 [42400/60000 (71%)]\tLoss: 0.574901\n",
      "Train Epoch: 1 [42560/60000 (71%)]\tLoss: 0.421874\n",
      "Train Epoch: 1 [42720/60000 (71%)]\tLoss: 0.634154\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.067845\n",
      "Train Epoch: 1 [43040/60000 (72%)]\tLoss: 0.275761\n",
      "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.233377\n",
      "Train Epoch: 1 [43360/60000 (72%)]\tLoss: 0.562564\n",
      "Train Epoch: 1 [43520/60000 (73%)]\tLoss: 0.217288\n",
      "Train Epoch: 1 [43680/60000 (73%)]\tLoss: 0.550633\n",
      "Train Epoch: 1 [43840/60000 (73%)]\tLoss: 0.103091\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.186663\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.180065\n",
      "Train Epoch: 1 [44320/60000 (74%)]\tLoss: 0.107882\n",
      "Train Epoch: 1 [44480/60000 (74%)]\tLoss: 0.328574\n",
      "Train Epoch: 1 [44640/60000 (74%)]\tLoss: 0.349014\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.322448\n",
      "Train Epoch: 1 [44960/60000 (75%)]\tLoss: 0.666991\n",
      "Train Epoch: 1 [45120/60000 (75%)]\tLoss: 0.424285\n",
      "Train Epoch: 1 [45280/60000 (75%)]\tLoss: 0.526303\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.248957\n",
      "Train Epoch: 1 [45600/60000 (76%)]\tLoss: 0.621889\n",
      "Train Epoch: 1 [45760/60000 (76%)]\tLoss: 0.986108\n",
      "Train Epoch: 1 [45920/60000 (77%)]\tLoss: 0.417397\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.577755\n",
      "Train Epoch: 1 [46240/60000 (77%)]\tLoss: 0.408778\n",
      "Train Epoch: 1 [46400/60000 (77%)]\tLoss: 0.192672\n",
      "Train Epoch: 1 [46560/60000 (78%)]\tLoss: 0.225681\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.346409\n",
      "Train Epoch: 1 [46880/60000 (78%)]\tLoss: 0.289454\n",
      "Train Epoch: 1 [47040/60000 (78%)]\tLoss: 0.164038\n",
      "Train Epoch: 1 [47200/60000 (79%)]\tLoss: 0.126511\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.274801\n",
      "Train Epoch: 1 [47520/60000 (79%)]\tLoss: 0.260954\n",
      "Train Epoch: 1 [47680/60000 (79%)]\tLoss: 0.359400\n",
      "Train Epoch: 1 [47840/60000 (80%)]\tLoss: 0.433569\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.314916\n",
      "Train Epoch: 1 [48160/60000 (80%)]\tLoss: 0.490595\n",
      "Train Epoch: 1 [48320/60000 (81%)]\tLoss: 0.585516\n",
      "Train Epoch: 1 [48480/60000 (81%)]\tLoss: 0.446601\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.167120\n",
      "Train Epoch: 1 [48800/60000 (81%)]\tLoss: 0.165036\n",
      "Train Epoch: 1 [48960/60000 (82%)]\tLoss: 0.263251\n",
      "Train Epoch: 1 [49120/60000 (82%)]\tLoss: 0.554326\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.816216\n",
      "Train Epoch: 1 [49440/60000 (82%)]\tLoss: 0.519611\n",
      "Train Epoch: 1 [49600/60000 (83%)]\tLoss: 0.219155\n",
      "Train Epoch: 1 [49760/60000 (83%)]\tLoss: 0.139895\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.293501\n",
      "Train Epoch: 1 [50080/60000 (83%)]\tLoss: 0.655975\n",
      "Train Epoch: 1 [50240/60000 (84%)]\tLoss: 0.119642\n",
      "Train Epoch: 1 [50400/60000 (84%)]\tLoss: 0.380153\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.262397\n",
      "Train Epoch: 1 [50720/60000 (85%)]\tLoss: 0.174608\n",
      "Train Epoch: 1 [50880/60000 (85%)]\tLoss: 0.584494\n",
      "Train Epoch: 1 [51040/60000 (85%)]\tLoss: 0.587765\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.280788\n",
      "Train Epoch: 1 [51360/60000 (86%)]\tLoss: 0.425326\n",
      "Train Epoch: 1 [51520/60000 (86%)]\tLoss: 0.509209\n",
      "Train Epoch: 1 [51680/60000 (86%)]\tLoss: 0.383689\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.325337\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.593466\n",
      "Train Epoch: 1 [52160/60000 (87%)]\tLoss: 0.220805\n",
      "Train Epoch: 1 [52320/60000 (87%)]\tLoss: 0.527173\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.461556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [52640/60000 (88%)]\tLoss: 0.143965\n",
      "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.060846\n",
      "Train Epoch: 1 [52960/60000 (88%)]\tLoss: 0.402965\n",
      "Train Epoch: 1 [53120/60000 (89%)]\tLoss: 0.666120\n",
      "Train Epoch: 1 [53280/60000 (89%)]\tLoss: 0.094808\n",
      "Train Epoch: 1 [53440/60000 (89%)]\tLoss: 0.161621\n",
      "Train Epoch: 1 [53600/60000 (89%)]\tLoss: 0.161098\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.076690\n",
      "Train Epoch: 1 [53920/60000 (90%)]\tLoss: 0.179043\n",
      "Train Epoch: 1 [54080/60000 (90%)]\tLoss: 0.545479\n",
      "Train Epoch: 1 [54240/60000 (90%)]\tLoss: 0.317569\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.182323\n",
      "Train Epoch: 1 [54560/60000 (91%)]\tLoss: 0.284475\n",
      "Train Epoch: 1 [54720/60000 (91%)]\tLoss: 0.223974\n",
      "Train Epoch: 1 [54880/60000 (91%)]\tLoss: 0.152636\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.171760\n",
      "Train Epoch: 1 [55200/60000 (92%)]\tLoss: 0.084221\n",
      "Train Epoch: 1 [55360/60000 (92%)]\tLoss: 0.241203\n",
      "Train Epoch: 1 [55520/60000 (93%)]\tLoss: 0.501817\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.637778\n",
      "Train Epoch: 1 [55840/60000 (93%)]\tLoss: 0.152106\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.401195\n",
      "Train Epoch: 1 [56160/60000 (94%)]\tLoss: 0.748104\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.417162\n",
      "Train Epoch: 1 [56480/60000 (94%)]\tLoss: 0.116794\n",
      "Train Epoch: 1 [56640/60000 (94%)]\tLoss: 0.486339\n",
      "Train Epoch: 1 [56800/60000 (95%)]\tLoss: 1.294498\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.482556\n",
      "Train Epoch: 1 [57120/60000 (95%)]\tLoss: 0.341231\n",
      "Train Epoch: 1 [57280/60000 (95%)]\tLoss: 1.121234\n",
      "Train Epoch: 1 [57440/60000 (96%)]\tLoss: 0.185518\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.425476\n",
      "Train Epoch: 1 [57760/60000 (96%)]\tLoss: 0.337846\n",
      "Train Epoch: 1 [57920/60000 (97%)]\tLoss: 0.268956\n",
      "Train Epoch: 1 [58080/60000 (97%)]\tLoss: 0.549632\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.124616\n",
      "Train Epoch: 1 [58400/60000 (97%)]\tLoss: 0.162748\n",
      "Train Epoch: 1 [58560/60000 (98%)]\tLoss: 0.108959\n",
      "Train Epoch: 1 [58720/60000 (98%)]\tLoss: 0.262689\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.378153\n",
      "Train Epoch: 1 [59040/60000 (98%)]\tLoss: 0.264507\n",
      "Train Epoch: 1 [59200/60000 (99%)]\tLoss: 0.657704\n",
      "Train Epoch: 1 [59360/60000 (99%)]\tLoss: 0.377556\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.318897\n",
      "Train Epoch: 1 [59680/60000 (99%)]\tLoss: 0.271251\n",
      "Train Epoch: 1 [59840/60000 (100%)]\tLoss: 0.234706\n",
      "\n",
      "Validation set: Avg. loss: 0.2150, Accuracy: 9361/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.287102\n",
      "Train Epoch: 2 [160/60000 (0%)]\tLoss: 0.151015\n",
      "Train Epoch: 2 [320/60000 (1%)]\tLoss: 0.494600\n",
      "Train Epoch: 2 [480/60000 (1%)]\tLoss: 0.253777\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.408035\n",
      "Train Epoch: 2 [800/60000 (1%)]\tLoss: 0.116334\n",
      "Train Epoch: 2 [960/60000 (2%)]\tLoss: 0.178910\n",
      "Train Epoch: 2 [1120/60000 (2%)]\tLoss: 0.404767\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.104522\n",
      "Train Epoch: 2 [1440/60000 (2%)]\tLoss: 0.314103\n",
      "Train Epoch: 2 [1600/60000 (3%)]\tLoss: 0.261930\n",
      "Train Epoch: 2 [1760/60000 (3%)]\tLoss: 0.337733\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.183625\n",
      "Train Epoch: 2 [2080/60000 (3%)]\tLoss: 0.234474\n",
      "Train Epoch: 2 [2240/60000 (4%)]\tLoss: 0.181074\n",
      "Train Epoch: 2 [2400/60000 (4%)]\tLoss: 0.294375\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.549580\n",
      "Train Epoch: 2 [2720/60000 (5%)]\tLoss: 0.542963\n",
      "Train Epoch: 2 [2880/60000 (5%)]\tLoss: 0.304751\n",
      "Train Epoch: 2 [3040/60000 (5%)]\tLoss: 0.387747\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.106153\n",
      "Train Epoch: 2 [3360/60000 (6%)]\tLoss: 0.413728\n",
      "Train Epoch: 2 [3520/60000 (6%)]\tLoss: 0.144890\n",
      "Train Epoch: 2 [3680/60000 (6%)]\tLoss: 0.300085\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.302760\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.183154\n",
      "Train Epoch: 2 [4160/60000 (7%)]\tLoss: 0.236303\n",
      "Train Epoch: 2 [4320/60000 (7%)]\tLoss: 0.793118\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.386410\n",
      "Train Epoch: 2 [4640/60000 (8%)]\tLoss: 0.175705\n",
      "Train Epoch: 2 [4800/60000 (8%)]\tLoss: 0.149053\n",
      "Train Epoch: 2 [4960/60000 (8%)]\tLoss: 0.592979\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.253650\n",
      "Train Epoch: 2 [5280/60000 (9%)]\tLoss: 0.486229\n",
      "Train Epoch: 2 [5440/60000 (9%)]\tLoss: 0.591003\n",
      "Train Epoch: 2 [5600/60000 (9%)]\tLoss: 0.156568\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.483854\n",
      "Train Epoch: 2 [5920/60000 (10%)]\tLoss: 0.120938\n",
      "Train Epoch: 2 [6080/60000 (10%)]\tLoss: 0.299134\n",
      "Train Epoch: 2 [6240/60000 (10%)]\tLoss: 0.505110\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.173265\n",
      "Train Epoch: 2 [6560/60000 (11%)]\tLoss: 0.377678\n",
      "Train Epoch: 2 [6720/60000 (11%)]\tLoss: 0.178595\n",
      "Train Epoch: 2 [6880/60000 (11%)]\tLoss: 0.257163\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.166733\n",
      "Train Epoch: 2 [7200/60000 (12%)]\tLoss: 0.233984\n",
      "Train Epoch: 2 [7360/60000 (12%)]\tLoss: 0.284146\n",
      "Train Epoch: 2 [7520/60000 (13%)]\tLoss: 0.562632\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.216466\n",
      "Train Epoch: 2 [7840/60000 (13%)]\tLoss: 0.252155\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.439808\n",
      "Train Epoch: 2 [8160/60000 (14%)]\tLoss: 0.403473\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.170732\n",
      "Train Epoch: 2 [8480/60000 (14%)]\tLoss: 0.404441\n",
      "Train Epoch: 2 [8640/60000 (14%)]\tLoss: 0.393941\n",
      "Train Epoch: 2 [8800/60000 (15%)]\tLoss: 0.671880\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.407504\n",
      "Train Epoch: 2 [9120/60000 (15%)]\tLoss: 0.411161\n",
      "Train Epoch: 2 [9280/60000 (15%)]\tLoss: 0.361914\n",
      "Train Epoch: 2 [9440/60000 (16%)]\tLoss: 0.287375\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.182975\n",
      "Train Epoch: 2 [9760/60000 (16%)]\tLoss: 0.253685\n",
      "Train Epoch: 2 [9920/60000 (17%)]\tLoss: 0.219495\n",
      "Train Epoch: 2 [10080/60000 (17%)]\tLoss: 0.366816\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.347233\n",
      "Train Epoch: 2 [10400/60000 (17%)]\tLoss: 0.706648\n",
      "Train Epoch: 2 [10560/60000 (18%)]\tLoss: 0.150922\n",
      "Train Epoch: 2 [10720/60000 (18%)]\tLoss: 0.319484\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.134457\n",
      "Train Epoch: 2 [11040/60000 (18%)]\tLoss: 0.275504\n",
      "Train Epoch: 2 [11200/60000 (19%)]\tLoss: 0.274773\n",
      "Train Epoch: 2 [11360/60000 (19%)]\tLoss: 0.377617\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.129212\n",
      "Train Epoch: 2 [11680/60000 (19%)]\tLoss: 0.261747\n",
      "Train Epoch: 2 [11840/60000 (20%)]\tLoss: 0.219099\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.328741\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.254222\n",
      "Train Epoch: 2 [12320/60000 (21%)]\tLoss: 0.123505\n",
      "Train Epoch: 2 [12480/60000 (21%)]\tLoss: 0.377956\n",
      "Train Epoch: 2 [12640/60000 (21%)]\tLoss: 0.141570\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.402282\n",
      "Train Epoch: 2 [12960/60000 (22%)]\tLoss: 0.107508\n",
      "Train Epoch: 2 [13120/60000 (22%)]\tLoss: 0.107536\n",
      "Train Epoch: 2 [13280/60000 (22%)]\tLoss: 0.305417\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.231704\n",
      "Train Epoch: 2 [13600/60000 (23%)]\tLoss: 0.362056\n",
      "Train Epoch: 2 [13760/60000 (23%)]\tLoss: 0.486249\n",
      "Train Epoch: 2 [13920/60000 (23%)]\tLoss: 0.620319\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.365043\n",
      "Train Epoch: 2 [14240/60000 (24%)]\tLoss: 0.131622\n",
      "Train Epoch: 2 [14400/60000 (24%)]\tLoss: 0.237520\n",
      "Train Epoch: 2 [14560/60000 (24%)]\tLoss: 0.269803\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.080308\n",
      "Train Epoch: 2 [14880/60000 (25%)]\tLoss: 0.162582\n",
      "Train Epoch: 2 [15040/60000 (25%)]\tLoss: 0.556906\n",
      "Train Epoch: 2 [15200/60000 (25%)]\tLoss: 0.122646\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.135993\n",
      "Train Epoch: 2 [15520/60000 (26%)]\tLoss: 0.110120\n",
      "Train Epoch: 2 [15680/60000 (26%)]\tLoss: 0.491248\n",
      "Train Epoch: 2 [15840/60000 (26%)]\tLoss: 0.275622\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.198420\n",
      "Train Epoch: 2 [16160/60000 (27%)]\tLoss: 0.354840\n",
      "Train Epoch: 2 [16320/60000 (27%)]\tLoss: 0.114594\n",
      "Train Epoch: 2 [16480/60000 (27%)]\tLoss: 0.237022\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.273735\n",
      "Train Epoch: 2 [16800/60000 (28%)]\tLoss: 0.374402\n",
      "Train Epoch: 2 [16960/60000 (28%)]\tLoss: 0.312034\n",
      "Train Epoch: 2 [17120/60000 (29%)]\tLoss: 0.237410\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.192437\n",
      "Train Epoch: 2 [17440/60000 (29%)]\tLoss: 0.162271\n",
      "Train Epoch: 2 [17600/60000 (29%)]\tLoss: 0.401601\n",
      "Train Epoch: 2 [17760/60000 (30%)]\tLoss: 0.048632\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.407239\n",
      "Train Epoch: 2 [18080/60000 (30%)]\tLoss: 0.333276\n",
      "Train Epoch: 2 [18240/60000 (30%)]\tLoss: 0.102079\n",
      "Train Epoch: 2 [18400/60000 (31%)]\tLoss: 0.416291\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.204511\n",
      "Train Epoch: 2 [18720/60000 (31%)]\tLoss: 0.185069\n",
      "Train Epoch: 2 [18880/60000 (31%)]\tLoss: 0.134370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [19040/60000 (32%)]\tLoss: 0.183835\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.099662\n",
      "Train Epoch: 2 [19360/60000 (32%)]\tLoss: 0.695910\n",
      "Train Epoch: 2 [19520/60000 (33%)]\tLoss: 0.257626\n",
      "Train Epoch: 2 [19680/60000 (33%)]\tLoss: 0.308927\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.063810\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.343207\n",
      "Train Epoch: 2 [20160/60000 (34%)]\tLoss: 0.178840\n",
      "Train Epoch: 2 [20320/60000 (34%)]\tLoss: 0.063116\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.149492\n",
      "Train Epoch: 2 [20640/60000 (34%)]\tLoss: 0.904707\n",
      "Train Epoch: 2 [20800/60000 (35%)]\tLoss: 0.675535\n",
      "Train Epoch: 2 [20960/60000 (35%)]\tLoss: 0.418517\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.074514\n",
      "Train Epoch: 2 [21280/60000 (35%)]\tLoss: 0.455997\n",
      "Train Epoch: 2 [21440/60000 (36%)]\tLoss: 0.231155\n",
      "Train Epoch: 2 [21600/60000 (36%)]\tLoss: 0.226694\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.074407\n",
      "Train Epoch: 2 [21920/60000 (37%)]\tLoss: 0.178232\n",
      "Train Epoch: 2 [22080/60000 (37%)]\tLoss: 0.546826\n",
      "Train Epoch: 2 [22240/60000 (37%)]\tLoss: 0.125750\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.411844\n",
      "Train Epoch: 2 [22560/60000 (38%)]\tLoss: 0.116726\n",
      "Train Epoch: 2 [22720/60000 (38%)]\tLoss: 0.434725\n",
      "Train Epoch: 2 [22880/60000 (38%)]\tLoss: 0.220911\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.402423\n",
      "Train Epoch: 2 [23200/60000 (39%)]\tLoss: 0.121949\n",
      "Train Epoch: 2 [23360/60000 (39%)]\tLoss: 0.207599\n",
      "Train Epoch: 2 [23520/60000 (39%)]\tLoss: 0.228935\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.219056\n",
      "Train Epoch: 2 [23840/60000 (40%)]\tLoss: 0.441611\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.332300\n",
      "Train Epoch: 2 [24160/60000 (40%)]\tLoss: 0.412560\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.220650\n",
      "Train Epoch: 2 [24480/60000 (41%)]\tLoss: 0.094653\n",
      "Train Epoch: 2 [24640/60000 (41%)]\tLoss: 0.160252\n",
      "Train Epoch: 2 [24800/60000 (41%)]\tLoss: 0.463873\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.097526\n",
      "Train Epoch: 2 [25120/60000 (42%)]\tLoss: 0.990252\n",
      "Train Epoch: 2 [25280/60000 (42%)]\tLoss: 0.197627\n",
      "Train Epoch: 2 [25440/60000 (42%)]\tLoss: 0.275136\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.110971\n",
      "Train Epoch: 2 [25760/60000 (43%)]\tLoss: 0.478501\n",
      "Train Epoch: 2 [25920/60000 (43%)]\tLoss: 0.219985\n",
      "Train Epoch: 2 [26080/60000 (43%)]\tLoss: 0.019401\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.152179\n",
      "Train Epoch: 2 [26400/60000 (44%)]\tLoss: 0.148812\n",
      "Train Epoch: 2 [26560/60000 (44%)]\tLoss: 0.103728\n",
      "Train Epoch: 2 [26720/60000 (45%)]\tLoss: 0.898828\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.396808\n",
      "Train Epoch: 2 [27040/60000 (45%)]\tLoss: 0.382932\n",
      "Train Epoch: 2 [27200/60000 (45%)]\tLoss: 0.144656\n",
      "Train Epoch: 2 [27360/60000 (46%)]\tLoss: 0.274888\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.200720\n",
      "Train Epoch: 2 [27680/60000 (46%)]\tLoss: 0.212228\n",
      "Train Epoch: 2 [27840/60000 (46%)]\tLoss: 0.342615\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.645589\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.673406\n",
      "Train Epoch: 2 [28320/60000 (47%)]\tLoss: 0.597021\n",
      "Train Epoch: 2 [28480/60000 (47%)]\tLoss: 0.172641\n",
      "Train Epoch: 2 [28640/60000 (48%)]\tLoss: 0.153119\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.357284\n",
      "Train Epoch: 2 [28960/60000 (48%)]\tLoss: 0.205839\n",
      "Train Epoch: 2 [29120/60000 (49%)]\tLoss: 0.503503\n",
      "Train Epoch: 2 [29280/60000 (49%)]\tLoss: 0.569783\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.287887\n",
      "Train Epoch: 2 [29600/60000 (49%)]\tLoss: 0.294824\n",
      "Train Epoch: 2 [29760/60000 (50%)]\tLoss: 0.077686\n",
      "Train Epoch: 2 [29920/60000 (50%)]\tLoss: 0.116805\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.819703\n",
      "Train Epoch: 2 [30240/60000 (50%)]\tLoss: 0.548242\n",
      "Train Epoch: 2 [30400/60000 (51%)]\tLoss: 0.103592\n",
      "Train Epoch: 2 [30560/60000 (51%)]\tLoss: 0.193512\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.201901\n",
      "Train Epoch: 2 [30880/60000 (51%)]\tLoss: 0.276677\n",
      "Train Epoch: 2 [31040/60000 (52%)]\tLoss: 0.138201\n",
      "Train Epoch: 2 [31200/60000 (52%)]\tLoss: 0.070385\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.166468\n",
      "Train Epoch: 2 [31520/60000 (53%)]\tLoss: 0.589416\n",
      "Train Epoch: 2 [31680/60000 (53%)]\tLoss: 0.107083\n",
      "Train Epoch: 2 [31840/60000 (53%)]\tLoss: 0.078182\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.121139\n",
      "Train Epoch: 2 [32160/60000 (54%)]\tLoss: 0.060677\n",
      "Train Epoch: 2 [32320/60000 (54%)]\tLoss: 0.082073\n",
      "Train Epoch: 2 [32480/60000 (54%)]\tLoss: 0.147901\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.366181\n",
      "Train Epoch: 2 [32800/60000 (55%)]\tLoss: 0.114695\n",
      "Train Epoch: 2 [32960/60000 (55%)]\tLoss: 0.080682\n",
      "Train Epoch: 2 [33120/60000 (55%)]\tLoss: 0.128098\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.213458\n",
      "Train Epoch: 2 [33440/60000 (56%)]\tLoss: 0.263485\n",
      "Train Epoch: 2 [33600/60000 (56%)]\tLoss: 0.218221\n",
      "Train Epoch: 2 [33760/60000 (56%)]\tLoss: 0.287331\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.371957\n",
      "Train Epoch: 2 [34080/60000 (57%)]\tLoss: 0.574836\n",
      "Train Epoch: 2 [34240/60000 (57%)]\tLoss: 0.248022\n",
      "Train Epoch: 2 [34400/60000 (57%)]\tLoss: 0.144145\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.184121\n",
      "Train Epoch: 2 [34720/60000 (58%)]\tLoss: 0.367925\n",
      "Train Epoch: 2 [34880/60000 (58%)]\tLoss: 0.301641\n",
      "Train Epoch: 2 [35040/60000 (58%)]\tLoss: 0.046701\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.122918\n",
      "Train Epoch: 2 [35360/60000 (59%)]\tLoss: 0.226401\n",
      "Train Epoch: 2 [35520/60000 (59%)]\tLoss: 0.028868\n",
      "Train Epoch: 2 [35680/60000 (59%)]\tLoss: 0.272697\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.058941\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.169685\n",
      "Train Epoch: 2 [36160/60000 (60%)]\tLoss: 0.309152\n",
      "Train Epoch: 2 [36320/60000 (61%)]\tLoss: 0.104665\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.308045\n",
      "Train Epoch: 2 [36640/60000 (61%)]\tLoss: 0.233261\n",
      "Train Epoch: 2 [36800/60000 (61%)]\tLoss: 0.075367\n",
      "Train Epoch: 2 [36960/60000 (62%)]\tLoss: 0.446448\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.502255\n",
      "Train Epoch: 2 [37280/60000 (62%)]\tLoss: 0.078210\n",
      "Train Epoch: 2 [37440/60000 (62%)]\tLoss: 0.111228\n",
      "Train Epoch: 2 [37600/60000 (63%)]\tLoss: 0.492835\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.238296\n",
      "Train Epoch: 2 [37920/60000 (63%)]\tLoss: 0.184937\n",
      "Train Epoch: 2 [38080/60000 (63%)]\tLoss: 0.224685\n",
      "Train Epoch: 2 [38240/60000 (64%)]\tLoss: 0.484616\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.076334\n",
      "Train Epoch: 2 [38560/60000 (64%)]\tLoss: 0.366048\n",
      "Train Epoch: 2 [38720/60000 (65%)]\tLoss: 0.106007\n",
      "Train Epoch: 2 [38880/60000 (65%)]\tLoss: 0.072582\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.096946\n",
      "Train Epoch: 2 [39200/60000 (65%)]\tLoss: 0.275126\n",
      "Train Epoch: 2 [39360/60000 (66%)]\tLoss: 0.877109\n",
      "Train Epoch: 2 [39520/60000 (66%)]\tLoss: 0.306738\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.162188\n",
      "Train Epoch: 2 [39840/60000 (66%)]\tLoss: 0.034069\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.553166\n",
      "Train Epoch: 2 [40160/60000 (67%)]\tLoss: 0.129039\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.349885\n",
      "Train Epoch: 2 [40480/60000 (67%)]\tLoss: 0.025732\n",
      "Train Epoch: 2 [40640/60000 (68%)]\tLoss: 0.402145\n",
      "Train Epoch: 2 [40800/60000 (68%)]\tLoss: 0.085645\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.570041\n",
      "Train Epoch: 2 [41120/60000 (69%)]\tLoss: 0.260990\n",
      "Train Epoch: 2 [41280/60000 (69%)]\tLoss: 0.178953\n",
      "Train Epoch: 2 [41440/60000 (69%)]\tLoss: 0.224141\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.412799\n",
      "Train Epoch: 2 [41760/60000 (70%)]\tLoss: 0.264441\n",
      "Train Epoch: 2 [41920/60000 (70%)]\tLoss: 0.608555\n",
      "Train Epoch: 2 [42080/60000 (70%)]\tLoss: 0.523091\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.300328\n",
      "Train Epoch: 2 [42400/60000 (71%)]\tLoss: 0.106538\n",
      "Train Epoch: 2 [42560/60000 (71%)]\tLoss: 0.234041\n",
      "Train Epoch: 2 [42720/60000 (71%)]\tLoss: 0.493013\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.211631\n",
      "Train Epoch: 2 [43040/60000 (72%)]\tLoss: 0.594630\n",
      "Train Epoch: 2 [43200/60000 (72%)]\tLoss: 0.036212\n",
      "Train Epoch: 2 [43360/60000 (72%)]\tLoss: 0.213334\n",
      "Train Epoch: 2 [43520/60000 (73%)]\tLoss: 0.186814\n",
      "Train Epoch: 2 [43680/60000 (73%)]\tLoss: 0.410568\n",
      "Train Epoch: 2 [43840/60000 (73%)]\tLoss: 0.277205\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.152586\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.251940\n",
      "Train Epoch: 2 [44320/60000 (74%)]\tLoss: 0.323978\n",
      "Train Epoch: 2 [44480/60000 (74%)]\tLoss: 0.632029\n",
      "Train Epoch: 2 [44640/60000 (74%)]\tLoss: 0.208185\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.160619\n",
      "Train Epoch: 2 [44960/60000 (75%)]\tLoss: 0.123258\n",
      "Train Epoch: 2 [45120/60000 (75%)]\tLoss: 0.114600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [45280/60000 (75%)]\tLoss: 0.444446\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.132148\n",
      "Train Epoch: 2 [45600/60000 (76%)]\tLoss: 0.164320\n",
      "Train Epoch: 2 [45760/60000 (76%)]\tLoss: 0.349455\n",
      "Train Epoch: 2 [45920/60000 (77%)]\tLoss: 0.154300\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.105591\n",
      "Train Epoch: 2 [46240/60000 (77%)]\tLoss: 0.507572\n",
      "Train Epoch: 2 [46400/60000 (77%)]\tLoss: 0.152692\n",
      "Train Epoch: 2 [46560/60000 (78%)]\tLoss: 0.439784\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.399712\n",
      "Train Epoch: 2 [46880/60000 (78%)]\tLoss: 0.218679\n",
      "Train Epoch: 2 [47040/60000 (78%)]\tLoss: 0.132305\n",
      "Train Epoch: 2 [47200/60000 (79%)]\tLoss: 0.387100\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.139780\n",
      "Train Epoch: 2 [47520/60000 (79%)]\tLoss: 0.320681\n",
      "Train Epoch: 2 [47680/60000 (79%)]\tLoss: 0.227880\n",
      "Train Epoch: 2 [47840/60000 (80%)]\tLoss: 0.153783\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.074470\n",
      "Train Epoch: 2 [48160/60000 (80%)]\tLoss: 0.330204\n",
      "Train Epoch: 2 [48320/60000 (81%)]\tLoss: 0.032120\n",
      "Train Epoch: 2 [48480/60000 (81%)]\tLoss: 0.170930\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.119657\n",
      "Train Epoch: 2 [48800/60000 (81%)]\tLoss: 0.255768\n",
      "Train Epoch: 2 [48960/60000 (82%)]\tLoss: 0.117507\n",
      "Train Epoch: 2 [49120/60000 (82%)]\tLoss: 0.048410\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.354233\n",
      "Train Epoch: 2 [49440/60000 (82%)]\tLoss: 0.437440\n",
      "Train Epoch: 2 [49600/60000 (83%)]\tLoss: 0.285185\n",
      "Train Epoch: 2 [49760/60000 (83%)]\tLoss: 0.504990\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.254870\n",
      "Train Epoch: 2 [50080/60000 (83%)]\tLoss: 0.750497\n",
      "Train Epoch: 2 [50240/60000 (84%)]\tLoss: 0.310089\n",
      "Train Epoch: 2 [50400/60000 (84%)]\tLoss: 0.427670\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.196389\n",
      "Train Epoch: 2 [50720/60000 (85%)]\tLoss: 0.300226\n",
      "Train Epoch: 2 [50880/60000 (85%)]\tLoss: 0.719837\n",
      "Train Epoch: 2 [51040/60000 (85%)]\tLoss: 0.295858\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.621767\n",
      "Train Epoch: 2 [51360/60000 (86%)]\tLoss: 0.179639\n",
      "Train Epoch: 2 [51520/60000 (86%)]\tLoss: 0.125914\n",
      "Train Epoch: 2 [51680/60000 (86%)]\tLoss: 0.395515\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.297870\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.206257\n",
      "Train Epoch: 2 [52160/60000 (87%)]\tLoss: 0.109674\n",
      "Train Epoch: 2 [52320/60000 (87%)]\tLoss: 0.197860\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.657802\n",
      "Train Epoch: 2 [52640/60000 (88%)]\tLoss: 0.090649\n",
      "Train Epoch: 2 [52800/60000 (88%)]\tLoss: 0.231857\n",
      "Train Epoch: 2 [52960/60000 (88%)]\tLoss: 0.444040\n",
      "Train Epoch: 2 [53120/60000 (89%)]\tLoss: 0.229808\n",
      "Train Epoch: 2 [53280/60000 (89%)]\tLoss: 0.081107\n",
      "Train Epoch: 2 [53440/60000 (89%)]\tLoss: 0.142033\n",
      "Train Epoch: 2 [53600/60000 (89%)]\tLoss: 0.119462\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.905168\n",
      "Train Epoch: 2 [53920/60000 (90%)]\tLoss: 0.115471\n",
      "Train Epoch: 2 [54080/60000 (90%)]\tLoss: 0.043247\n",
      "Train Epoch: 2 [54240/60000 (90%)]\tLoss: 0.182587\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.325649\n",
      "Train Epoch: 2 [54560/60000 (91%)]\tLoss: 0.321592\n",
      "Train Epoch: 2 [54720/60000 (91%)]\tLoss: 0.109494\n",
      "Train Epoch: 2 [54880/60000 (91%)]\tLoss: 0.165933\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.407948\n",
      "Train Epoch: 2 [55200/60000 (92%)]\tLoss: 0.163989\n",
      "Train Epoch: 2 [55360/60000 (92%)]\tLoss: 0.708466\n",
      "Train Epoch: 2 [55520/60000 (93%)]\tLoss: 0.949294\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.179635\n",
      "Train Epoch: 2 [55840/60000 (93%)]\tLoss: 0.333440\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.722637\n",
      "Train Epoch: 2 [56160/60000 (94%)]\tLoss: 0.267156\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.268199\n",
      "Train Epoch: 2 [56480/60000 (94%)]\tLoss: 0.316843\n",
      "Train Epoch: 2 [56640/60000 (94%)]\tLoss: 0.253881\n",
      "Train Epoch: 2 [56800/60000 (95%)]\tLoss: 0.424742\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.172057\n",
      "Train Epoch: 2 [57120/60000 (95%)]\tLoss: 0.139082\n",
      "Train Epoch: 2 [57280/60000 (95%)]\tLoss: 0.131145\n",
      "Train Epoch: 2 [57440/60000 (96%)]\tLoss: 0.661917\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.292837\n",
      "Train Epoch: 2 [57760/60000 (96%)]\tLoss: 0.304406\n",
      "Train Epoch: 2 [57920/60000 (97%)]\tLoss: 0.148692\n",
      "Train Epoch: 2 [58080/60000 (97%)]\tLoss: 0.328664\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.440451\n",
      "Train Epoch: 2 [58400/60000 (97%)]\tLoss: 1.024382\n",
      "Train Epoch: 2 [58560/60000 (98%)]\tLoss: 0.332720\n",
      "Train Epoch: 2 [58720/60000 (98%)]\tLoss: 0.386859\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.407529\n",
      "Train Epoch: 2 [59040/60000 (98%)]\tLoss: 0.121291\n",
      "Train Epoch: 2 [59200/60000 (99%)]\tLoss: 0.323305\n",
      "Train Epoch: 2 [59360/60000 (99%)]\tLoss: 0.253650\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.254160\n",
      "Train Epoch: 2 [59680/60000 (99%)]\tLoss: 0.333372\n",
      "Train Epoch: 2 [59840/60000 (100%)]\tLoss: 0.225174\n",
      "\n",
      "Validation set: Avg. loss: 0.1552, Accuracy: 9521/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.630599\n",
      "Train Epoch: 3 [160/60000 (0%)]\tLoss: 0.306032\n",
      "Train Epoch: 3 [320/60000 (1%)]\tLoss: 0.435202\n",
      "Train Epoch: 3 [480/60000 (1%)]\tLoss: 0.264152\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.179725\n",
      "Train Epoch: 3 [800/60000 (1%)]\tLoss: 0.073182\n",
      "Train Epoch: 3 [960/60000 (2%)]\tLoss: 0.049142\n",
      "Train Epoch: 3 [1120/60000 (2%)]\tLoss: 0.031836\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.157370\n",
      "Train Epoch: 3 [1440/60000 (2%)]\tLoss: 0.178008\n",
      "Train Epoch: 3 [1600/60000 (3%)]\tLoss: 0.042754\n",
      "Train Epoch: 3 [1760/60000 (3%)]\tLoss: 0.241027\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.036077\n",
      "Train Epoch: 3 [2080/60000 (3%)]\tLoss: 0.114019\n",
      "Train Epoch: 3 [2240/60000 (4%)]\tLoss: 0.287650\n",
      "Train Epoch: 3 [2400/60000 (4%)]\tLoss: 0.573101\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.165206\n",
      "Train Epoch: 3 [2720/60000 (5%)]\tLoss: 0.175069\n",
      "Train Epoch: 3 [2880/60000 (5%)]\tLoss: 0.234399\n",
      "Train Epoch: 3 [3040/60000 (5%)]\tLoss: 0.364717\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.586996\n",
      "Train Epoch: 3 [3360/60000 (6%)]\tLoss: 0.202580\n",
      "Train Epoch: 3 [3520/60000 (6%)]\tLoss: 0.249977\n",
      "Train Epoch: 3 [3680/60000 (6%)]\tLoss: 0.403961\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.392292\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.015046\n",
      "Train Epoch: 3 [4160/60000 (7%)]\tLoss: 0.225384\n",
      "Train Epoch: 3 [4320/60000 (7%)]\tLoss: 0.620394\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.693118\n",
      "Train Epoch: 3 [4640/60000 (8%)]\tLoss: 0.414239\n",
      "Train Epoch: 3 [4800/60000 (8%)]\tLoss: 0.239238\n",
      "Train Epoch: 3 [4960/60000 (8%)]\tLoss: 0.582703\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.031926\n",
      "Train Epoch: 3 [5280/60000 (9%)]\tLoss: 0.178730\n",
      "Train Epoch: 3 [5440/60000 (9%)]\tLoss: 0.120119\n",
      "Train Epoch: 3 [5600/60000 (9%)]\tLoss: 0.125774\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.070211\n",
      "Train Epoch: 3 [5920/60000 (10%)]\tLoss: 0.472488\n",
      "Train Epoch: 3 [6080/60000 (10%)]\tLoss: 0.020513\n",
      "Train Epoch: 3 [6240/60000 (10%)]\tLoss: 0.135554\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.333415\n",
      "Train Epoch: 3 [6560/60000 (11%)]\tLoss: 0.531734\n",
      "Train Epoch: 3 [6720/60000 (11%)]\tLoss: 0.308605\n",
      "Train Epoch: 3 [6880/60000 (11%)]\tLoss: 0.512498\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.241804\n",
      "Train Epoch: 3 [7200/60000 (12%)]\tLoss: 0.198513\n",
      "Train Epoch: 3 [7360/60000 (12%)]\tLoss: 0.249719\n",
      "Train Epoch: 3 [7520/60000 (13%)]\tLoss: 0.459319\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.568680\n",
      "Train Epoch: 3 [7840/60000 (13%)]\tLoss: 0.087725\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.485072\n",
      "Train Epoch: 3 [8160/60000 (14%)]\tLoss: 0.130667\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.068306\n",
      "Train Epoch: 3 [8480/60000 (14%)]\tLoss: 0.277888\n",
      "Train Epoch: 3 [8640/60000 (14%)]\tLoss: 0.088147\n",
      "Train Epoch: 3 [8800/60000 (15%)]\tLoss: 0.290144\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.098020\n",
      "Train Epoch: 3 [9120/60000 (15%)]\tLoss: 0.587131\n",
      "Train Epoch: 3 [9280/60000 (15%)]\tLoss: 0.524831\n",
      "Train Epoch: 3 [9440/60000 (16%)]\tLoss: 0.353816\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.483508\n",
      "Train Epoch: 3 [9760/60000 (16%)]\tLoss: 0.500155\n",
      "Train Epoch: 3 [9920/60000 (17%)]\tLoss: 0.087150\n",
      "Train Epoch: 3 [10080/60000 (17%)]\tLoss: 0.181570\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.496157\n",
      "Train Epoch: 3 [10400/60000 (17%)]\tLoss: 0.550875\n",
      "Train Epoch: 3 [10560/60000 (18%)]\tLoss: 0.082628\n",
      "Train Epoch: 3 [10720/60000 (18%)]\tLoss: 0.362010\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.238055\n",
      "Train Epoch: 3 [11040/60000 (18%)]\tLoss: 0.565458\n",
      "Train Epoch: 3 [11200/60000 (19%)]\tLoss: 0.700494\n",
      "Train Epoch: 3 [11360/60000 (19%)]\tLoss: 0.208102\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.099134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [11680/60000 (19%)]\tLoss: 0.276546\n",
      "Train Epoch: 3 [11840/60000 (20%)]\tLoss: 0.070094\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.294031\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.098997\n",
      "Train Epoch: 3 [12320/60000 (21%)]\tLoss: 0.200923\n",
      "Train Epoch: 3 [12480/60000 (21%)]\tLoss: 0.067425\n",
      "Train Epoch: 3 [12640/60000 (21%)]\tLoss: 0.244853\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.463882\n",
      "Train Epoch: 3 [12960/60000 (22%)]\tLoss: 0.384583\n",
      "Train Epoch: 3 [13120/60000 (22%)]\tLoss: 0.481972\n",
      "Train Epoch: 3 [13280/60000 (22%)]\tLoss: 0.782684\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.760602\n",
      "Train Epoch: 3 [13600/60000 (23%)]\tLoss: 0.084961\n",
      "Train Epoch: 3 [13760/60000 (23%)]\tLoss: 0.248102\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m validation()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m   \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   validation()\n",
      "Cell \u001b[0;32mIn [18], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m output \u001b[38;5;241m=\u001b[39m network(data)\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m log_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# !mkdir results\n",
    "validation()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e172bd-ba46-4109-8e1b-c0b70cad0fd5",
   "metadata": {},
   "source": [
    "# Tracez les performances d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676fb971-a9b2-488f-b640-51a6afec48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(validation_counter, validation_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e815f6-f24e-4875-bb39-ad221536b4c0",
   "metadata": {},
   "source": [
    "# Passez sur GPU\n",
    "Modifiez maintenant le code pour l'exécuter sur GPU et comparez la vitesse d'exécution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacec199-ccf0-4ce9-9a2b-3fb6c299b8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a067d4-32b8-4d71-8ca6-90096387e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = network()\n",
    "# net = net.to('cuda')\n",
    "# for (data,target in ())\n",
    "\n",
    "# output = net(data.to('cuda'))\n",
    "\n",
    "# loss = loss(output,target.to('cuda'))\n",
    "# loss.item()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
